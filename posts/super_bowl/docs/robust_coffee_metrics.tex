\documentclass{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}

% Code Listing Configuration
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% Page Geometry
\geometry{a4paper, margin=1in}

% Title Information
\title{Home Brew Advantage: The Gravitational Influence of Regional Coffee Chains on Super Bowl LX}
\author{\textit{Ministry of Silly Plots}}
\date{February 4, 2026}

\begin{document}

\maketitle

\begin{abstract}
This study investigates the correlation between the gravitational relativity of regional coffee chains (Starbucks vs. Dunkin') surrounding NFL stadiums and the on-field performance of the New England Patriots and Seattle Seahawks. We conduct a natural experiment with control variables using play by play data from the 2025 NFL season, notably isolating Away Games to eliminate Home Field Advantage bias. We identify a striking and robust performance separation that aligns with the ``Home Brew Advantage'' hypothesis. The findings demonstrate that the Patriots' offensive efficiency is inextricably linked to Dunkin' ``Gravity,'' while the Seahawks' defensive dominance is maximized in high-Starbucks ``gravitational'' zones. We discuss the implications of these findings for the upcoming Super Bowl LX.
\end{abstract}

\section{Introduction}

Despite the NFL's embrace of Next Gen Stats, top analytics experts league-wide have yet to explore the impact of the caffeine environment surrounding the stadium on team performance. This paper proposes a novel environmental variable: the ``Regional Coffee Chain Gravitational Relativity.'' We hypothesize that the regional dominance of major coffee chains exerts a measurable influence on team performance, specifically for teams with strong cultural associations to those brands.

We propose the following hypotheses:
\begin{itemize}
    \item \textbf{H1 (Patriots):} The Pats Run on Dunkin'.The New England Patriots offense performs better in environments with high relative \textbf{Dunkin' Gravity} ($G_{net} > 0$).
    \item \textbf{H2 (Seahawks):} The Legion of Brew. The Seattle Seahawks defense performs better in environments with high relative \textbf{Starbucks Gravity} ($G_{net} < 0$).
    \item \textbf{H3 (Null Hypothesis):} These performance deltas are solely artifacts of Home Field Advantage.
\end{itemize}

\section{Methodology}

\subsection{The Coffee Gravity Model}

To quantify the ``coffee gravity'' of each stadium, we employed an \textbf{Interference-Adjusted Exponential Decay Model}. Conventional density metrics fail to account for proximity; a coffee shop adjacent to the stadium should carry more weight than one ten miles away.

The gravitational pull $G_{chain}$ for a given chain is calculated as:

\begin{equation}
    G_{chain} = \sum_{i=0}^{n} M_i \cdot e^{-0.5 \cdot d_i}
\end{equation}

Where:
\begin{itemize}
    \item $d_i$ is the Haversine distance (in miles) from the stadium to location $i$, defined as:
    \begin{equation}
        d = 2r \arcsin\left(\sqrt{\sin^2\left(\frac{\phi_2 - \phi_1}{2}\right) + \cos(\phi_1) \cos(\phi_2) \sin^2\left(\frac{\lambda_2 - \lambda_1}{2}\right)}\right)
    \end{equation}
    where $\phi$ represents latitude, $\lambda$ represents longitude, and $r$ is the radius of the Earth (approx. 3959 miles).
    \item $M_i$ is the ``Mass'' of location $i$, initialized at 1.0.
\end{itemize}

\subsubsection{Interference Term}
To account for market saturation and competition, we introduced an interference term. The mass $M_i$ is reduced if a competitor's location is within an \textbf{Interference Radius} ($r = 0.5$ miles). As direct competitors with a distinct regional split, we treat Starbucks and Dunkin' as mutually exclusive and assume that the presence of one negates the gravitational pull of the other.

\begin{equation}
    M_i' = M_i - \left(1.0 - \frac{d_{competitor}}{0.5}\right)
\end{equation}

The Net Gravity ($G_{net}$) is defined as the difference between the two forces:

\begin{equation}
    G_{net} = G_{dunkin} - G_{starbucks}
\end{equation}

Positive values indicate a Dunkin'-dominant environment, while negative values indicate a Starbucks-dominant environment.

\subsection{Control Variables}

Home field advantage is a clear confounding variable in this analysis, since teams play better at home in general and the two teams in question have particular strong gravitational fields for their respective coffee chains. To address this, we applied a strict \textbf{Away Games Only} filter. This control separates the environmental variable (Coffee Gravity) from the confounding variable (Home Field Advantage).

\subsection{Data Sources}

The analysis utilizes data from the 2025 NFL Season (Regular Season + Playoffs). Game data was sourced from \texttt{nflverse} Play-by-Play data via BigQuery, filtered for \texttt{season\_type IN ('REG', 'POST')}. Location data consists of geocoded coordinates of all US Starbucks and Dunkin' locations.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{screenshots/New_England_Patriots_Gillette_Stadium.png}
        \caption{Gillette Stadium (High Dunkin' Gravity)}
        \label{fig:gillette}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{screenshots/Seattle_Seahawks_Lumen_Field.png}
        \caption{Lumen Field (High Starbucks Gravity)}
        \label{fig:lumen}
    \end{subfigure}
    \caption{Visualizing the Coffee Gravity Field: Clean screenshots of stadium environments used for density calculation.}
    \label{fig:stadiums}
\end{figure}

\section{Results}

\subsection{The Patriots ``Run on Dunkin'' (Confirmed)}

Analyzing \textbf{Away Games Only}, the Patriots offense shows a drastic drop in production when entering ``Starbucks Gravitational Zones'' ($G_{net} < 0$). This is primarily driven by a collapse in the rushing attack.

\begin{table}[H]
    \centering
    \caption{Patriots Offensive Metrics (Away Games Only)}
    \begin{tabular}{lccl}
        \toprule
        \textbf{Metric} & \textbf{Dunkin Zone} & \textbf{Starbucks Zone} & \textbf{Diff} \\
         & ($G_{net} > 0$) & ($G_{net} < 0$) & \\
        \midrule
        Points Per Game & 31.3 & 24.0 & \textbf{-7.3} \\
        Total Yds / Game & 409.7 & 338.5 & \textbf{-71.2} \\
        Rush EPA / Play & +0.053 & -0.186 & \textbf{-0.239} \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Conclusion:} H1 is \textbf{Empirically Validated}. The data reveals a binary mode of performance: in Dunkin' zones, the offense operates at an elite efficiency; in Starbucks zones, production collapses across all key vectors.

\subsection{The Seahawks ``Legion of Brew'' (Confirmed)}

Conversely, the Seahawks defense exhibits elite performance metrics in ``Starbucks Gravitational Zones.''

\begin{table}[H]
    \centering
    \caption{Seahawks Defensive Metrics (Away Games Only)}
    \begin{tabular}{lccl}
        \toprule
        \textbf{Metric} & \textbf{Dunkin Zone} & \textbf{Starbucks Zone} & \textbf{Diff} \\
         & ($G_{net} > 0$) & ($G_{net} < 0$) & \\
        \midrule
        Total Turnovers & 4 & 9 & \textbf{+5} \\
        Turnovers / Game & 1.00 & 1.80 & \textbf{+0.80} \\
        PPG Allowed & 14.8 & 14.2 & \textbf{-0.6} \\
        Opp. Passer Rtg & 70.3 & 61.6 & \textbf{-8.7} \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Conclusion:} H2 is \textbf{Strongly Supported}. The Starbucks atmosphere correlates with a massive +80\% increase in forced turnovers (1.8 vs 1.0 per game), providing strong evidence for the environmental influence of the coffee ecosystem.

\subsection{Outlier Discovery: The Sam Darnold Paradox}

An unexpected finding emerged regarding Seahawks QB Sam Darnold. Unlike his team's defense, Darnold exhibits a strong \textbf{negative correlation} with Starbucks Gravity.

\begin{table}[H]
    \centering
    \caption{Sam Darnold Performance Splits}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Metric} & \textbf{Dunkin Zone} & \textbf{Starbucks Zone} & \textbf{Diff} \\
        \midrule
        Passer Rating & 124.4 & 75.4 & \textbf{-49.0} \\
        TD / INT Ratio & 5.50 & 0.57 & \textbf{-4.93} \\
        Points Per Game & 31.2 & 22.6 & \textbf{-8.6} \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Interpretation:} Darnold's passer rating drops by a staggering \textbf{49 points} (124.4 to 75.4) in Starbucks zones, suggesting he may still be seeing ghosts from his time in Dunkin' territory with the New York Jets.

\section{Discussion: Super Bowl LX Preview}

Super Bowl LX will be held at \textbf{Levi's Stadium} in Santa Clara, CA. Our model calculates the Net Gravity of this location to be \textbf{-5.80}, the second most Starbucks-dominant stadium in the league, behind only the Seahawks' own Lumen Field. It also has higher Starbucks Gravity than the Patriots' home stadium, Gillette Stadium has Dunkin' gravity. Assuming equal Dunkin' and Starbucks gravitational effects for both teams, the Patriots are at a significant disadvantage.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{screenshots/San_Francisco_49ers_Levi's_Stadium.png}
    \caption{Levi's Stadium: A Starbucks stronghold ($G_{net} = -5.80$).}
    \label{fig:levis}
\end{figure}

Based on the robust ``Away Games Only'' model, we project the following outcomes:
\begin{enumerate}
    \item \textbf{Patriots Offense:} Predicted to underperform ($\approx$ 24 PPG, -0.186 rushing EPA/play).
    \item \textbf{Seahawks Defense:} Predicted to dominate ($\approx$ 12 PPG allowed, +80\% increase in takeaways).
    \item \textbf{Variable:} Sam Darnold is predicted to struggle significantly (75.4 Passer Rating), though the Seahawks defense is likely to slow down Drake Maye even more, holding opposing QBs to a 61.6 passer rating in Starbucks zones.
\end{enumerate}

\textbf{Prediction:} The environmental factors heavily favor a \textbf{Seahawks Defensive Victory}, provided their run game can compensate for the predicted Quarterback inefficiency.

\newpage
\section{Code Artifacts \& Reproducibility}

All analysis code is available in the project repository at:

\begin{center}
\url{https://github.com/charlie86/sillyplots/tree/main/posts/super_bowl}
\end{center}

\subsection{Order of Operations}

To reproduce this analysis from scratch:

\begin{enumerate}
    \item \textbf{Install dependencies:} \texttt{pip install -r requirements.txt}
    \item \textbf{Load PBP data to BigQuery:} \texttt{python etl/load\_data.py}
    \item \textbf{Scrape coffee locations:} \texttt{python etl/scrape\_coffee\_locations.py}
    \item \textbf{Run analysis:} \texttt{python analysis/robust\_coffee\_check.py}
    \item \textbf{Generate visualizations:} \texttt{python visualization/generate\_map.py}
\end{enumerate}

\subsection{Key Scripts}

\noindent \textbf{ETL Scripts:}
\begin{itemize}
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/etl/load_data.py}{\texttt{etl/load\_data.py}} -- Loads nflverse PBP data to BigQuery
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/etl/scrape_coffee_locations.py}{\texttt{etl/scrape\_coffee\_locations.py}} -- Scrapes coffee locations via Google Maps API
\end{itemize}

\noindent \textbf{Analysis \& Visualization:}
\begin{itemize}
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/analysis/robust_coffee_check.py}{\texttt{analysis/robust\_coffee\_check.py}} -- Main analysis script
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/analysis/reproduce_robust_metrics.sql}{\texttt{analysis/reproduce\_robust\_metrics.sql}} -- Reproducible SQL queries
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/visualization/generate_map.py}{\texttt{visualization/generate\_map.py}} -- Interactive gravity field map
    \item \href{https://github.com/charlie86/sillyplots/blob/main/posts/super_bowl/visualization/plot_gravity_chart.py}{\texttt{visualization/plot\_gravity\_chart.py}} -- Net gravity ranking chart
\end{itemize}

\newpage
\appendix
\section{Net Gravity Rankings}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{coffee_gravity_ranking_publication.jpeg}
    \caption{Home Brew Advantage: Net Coffee Gravity for all NFL teams. Stadiums below the dashed line have higher Dunkin' gravity; stadiums above the dashed line have higher Starbucks gravity.}
    \label{fig:ranking}
\end{figure}

\section{Algorithm Reference}

To ensure full reproducibility and transparency of the Coffee Gravity Model, we include the core Python implementations used for data collection and analysis.

\subsection{The Gravity Model}
The core interference-adjusted gravity calculation. Note the specific handling of the ``Interference Radius'' to model the Dunkin-Starbucks exclusion principle.

\begin{lstlisting}[language=Python, caption=Coffee Gravity Calculation]
def calculate_stadium_gravity_single(stadium_lat, stadium_lng, d_locs, s_locs):
    """
    Calculate net gravity at a stadium using the interference model
    Returns: (dunkin_gravity, starbucks_gravity, net_gravity)
    """
    INTERFERENCE_RADIUS = 0.5  # miles
    INTERFERENCE_STRENGTH = 1.0
    
    if len(d_locs) == 0 and len(s_locs) == 0:
        return 0.0, 0.0, 0.0
    
    # Initialize masses
    d_masses = np.ones(len(d_locs))
    s_masses = np.ones(len(s_locs))
    
    # Apply interference reduction
    if len(d_locs) > 0 and len(s_locs) > 0:
        for i, d in enumerate(d_locs):
            for j, s in enumerate(s_locs):
                dist = simple_hav(d['lng'], d['lat'], s['lng'], s['lat'])
                if dist < INTERFERENCE_RADIUS:
                    reduction = INTERFERENCE_STRENGTH * (1.0 - dist/INTERFERENCE_RADIUS)
                    d_masses[i] -= reduction
                    s_masses[j] -= reduction
        d_masses = np.maximum(d_masses, 0.0)
        s_masses = np.maximum(s_masses, 0.0)
    
    # Calculate gravity at stadium location
    dunkin_gravity = 0.0
    starbucks_gravity = 0.0
    
    for i, loc in enumerate(d_locs):
        if d_masses[i] > 0:
            dist = simple_hav(loc['lng'], loc['lat'], stadium_lng, stadium_lat)
            dunkin_gravity += d_masses[i] * np.exp(-0.5 * dist)
    
    for i, loc in enumerate(s_locs):
        if s_masses[i] > 0:
            dist = simple_hav(loc['lng'], loc['lat'], stadium_lng, stadium_lat)
            starbucks_gravity += s_masses[i] * np.exp(-0.5 * dist)
    
    # Net Gravity: Starbucks (Positive) - Dunkin (Negative)
    net_gravity = starbucks_gravity - dunkin_gravity
    return dunkin_gravity, starbucks_gravity, net_gravity
\end{lstlisting}

\subsection{Geospatial Data Collection}
We utilized the Google Places API to identify all relevant locations within a 10-mile radius.

\begin{lstlisting}[language=Python, caption=Google Maps API Iteration]
def find_all_places_nearby(gmaps, lat, lng, keyword, radius_meters):
    places = []
    next_page_token = None
    
    while True:
        try:
            params = {
                'location': (lat, lng),
                'keyword': keyword,
                'radius': radius_meters,
                'type': 'restaurant'
            }
            if next_page_token:
                params['page_token'] = next_page_token

            result = gmaps.places_nearby(**params)
            
            if result.get('results'):
                for place in result['results']:
                    name = place.get('name', '')
                    if keyword.lower() in name.lower() or name.lower() in keyword.lower():
                        loc = place['geometry']['location']
                        dist = haversine_distance(lat, lng, loc['lat'], loc['lng'])
                        places.append({
                            'name': name,
                            'lat': loc['lat'],
                            'lng': loc['lng'],
                            'distance_miles': round(dist, 4)
                        })
            
            next_page_token = result.get('next_page_token')
            if not next_page_token:
                break
            
            time.sleep(2) 
            
        except Exception as e:
            print(f"Error in places search: {e}")
            break
            
    return places
\end{lstlisting}

\subsection{Metric Calculation (Rush EPA)}
The calculation of efficiency metrics, illustrating how we derive the specific ``Rush EPA'' that proved critical for analyzing the Patriots' performance drop-off.

\begin{lstlisting}[language=Python, caption=Offensive Efficiency Logic]
def calculate_metrics_offense(df, team):
    metrics = {}
    
    # Completion %
    attempts = team_df['pass_attempt'].sum()
    completions = team_df['complete_pass'].sum()
    metrics['Comp %'] = (completions / attempts * 100) if attempts > 0 else 0.0
    
    # Rush EPA
    rush_plays = team_df[team_df['play_type'] == 'run']
    rush_epa = rush_plays['epa'].mean()
    metrics['Rush EPA'] = rush_epa if not np.isnan(rush_epa) else 0.0
    
    # Sack Rate
    sacks = team_df['sack'].sum()
    dropbacks = attempts + sacks
    metrics['Sack Rate'] = (sacks / dropbacks * 100) if dropbacks > 0 else 0.0

    return metrics
\end{lstlisting}

\subsection{Metric Calculation (Defensive Turnovers)}
The defense-specific logic, highlighting the turnover aggregation and points allowed.

\begin{lstlisting}[language=Python, caption=Defensive Metrics Logic]
def calculate_metrics_defense(df, team):
    metrics = {}
    
    # PPG Allowed
    game_scores_allowed = []
    for gid in team_df['game_id'].unique():
        g = team_df[team_df['game_id'] == gid].iloc[0]
        if g['home_team'] == team:
            game_scores_allowed.append(g['away_score']) 
        else:
            game_scores_allowed.append(g['home_score'])
    metrics['PPG Allowed'] = np.mean(game_scores_allowed) if game_scores_allowed else 0.0
    
    # Turnovers (Defense)
    ints = team_df['interception'].sum()
    fumbles = team_df['fumble_lost'].sum()
    metrics['Turnovers'] = ints + fumbles

    return metrics
\end{lstlisting}

\end{document}
